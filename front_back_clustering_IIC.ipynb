{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce05fa1-d985-4c66-9316-3e4a698f68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import cv2\n",
    "import plotly.express as px\n",
    "\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from ipywidgets import interact\n",
    "from img_plots import make_badge_scatter\n",
    "from typing import Callable\n",
    "from matplotlib.offsetbox import OffsetImage\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c858fe8-885a-4118-a046-d052b8016c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f1f45-cefd-4dd4-b4a8-b6e1dd3c9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'archive'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea3bf3-630a-4b8e-b1b2-1f7b81bd6401",
   "metadata": {},
   "source": [
    "Load data from the previous stage (front back clustering initial view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c3773-f3cb-46e4-a96e-3f95fa94a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = join(DATA_FOLDER, 'cropped_edge_imgs_order_fix.joblib')\n",
    "LOAD_DF_INFO_PATH = join(DATA_FOLDER, 'cropped_edge_imgs_info.csv')\n",
    "\n",
    "with open(LOAD_PATH, 'rb') as fin:\n",
    "    data = joblib.load(fin)\n",
    "\n",
    "cat_name_df = pd.read_csv(LOAD_DF_INFO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a85d2-650a-4168-b1bc-195ce9848904",
   "metadata": {},
   "source": [
    "# Resize each class to fixed shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0953b-a4da-4dad-81e5-4a702b53eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_LOAD = False\n",
    "IS_SAVE = False\n",
    "SAVE_PATH = join(DATA_FOLDER, 'resized_data_arr.joblib')\n",
    "\n",
    "if not os.path.exists(SAVE_PATH) or FORCE_LOAD:\n",
    "    data_arr = dict()\n",
    "    \n",
    "    for _, iter_row in cat_name_df.iterrows():\n",
    "    \n",
    "        iter_class = str(iter_row['class'])\n",
    "        front_back_keys = iter_row['front_back_keys']\n",
    "    \n",
    "        iter_elements = [\n",
    "            el for k, el in data.items()\n",
    "            if k.split('_')[0] == iter_class\n",
    "            and k not in front_back_keys\n",
    "        ]\n",
    "        med_y = int(np.median([el.shape[0] for el in iter_elements]))\n",
    "        med_x = int(np.median([el.shape[1] for el in iter_elements]))\n",
    "    \n",
    "        iter_X = np.concatenate(\n",
    "            [\n",
    "                np.expand_dims(\n",
    "                    np.expand_dims(\n",
    "                        cv2.resize(img, [med_x, med_y]).astype(np.int32),\n",
    "                        axis=0\n",
    "                    ),\n",
    "                    axis=-1\n",
    "                )\n",
    "                for img in iter_elements\n",
    "            ]\n",
    "        )\n",
    "        data_arr[iter_class] = iter_X\n",
    "else:\n",
    "    print('loading from file...')\n",
    "    with open(SAVE_PATH, 'rb') as fin:\n",
    "        data_arr = joblib.load(fin)\n",
    "if IS_SAVE:\n",
    "    with open(SAVE_PATH, 'wb') as fout:\n",
    "        joblib.dump(data_arr, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b26cca-a2ff-4191-b6e8-110a179f074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IICDataPairGenerator(Sequence):\n",
    "\n",
    "\n",
    "    def __init__(self, sample_X,\n",
    "                 transform_generator: ImageDataGenerator,\n",
    "                 batch_size: int) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_X = sample_X\n",
    "        self.transform_generator = transform_generator\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Image sample Indexes for the current batch\n",
    "        \"\"\"\n",
    "        start_index = index * self.batch_size\n",
    "        end_index = (index + 1) * self.batch_size\n",
    "\n",
    "        X_transformed = np.concatenate([\n",
    "            next(\n",
    "                self.transform_generator.flow(\n",
    "                     self.sample_X[i:(i + 1), :]\n",
    "                )\n",
    "            )\n",
    "            for i in range(start_index, end_index)\n",
    "        ])\n",
    "        result_X = np.concatenate([\n",
    "            self.sample_X[start_index:end_index, :],\n",
    "            X_transformed\n",
    "        ])\n",
    "        return result_X, result_X\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.sample_X.shape[0] / self.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7677ca5-48b9-407c-9d8c-6b41b7644e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILoss(tf.keras.losses.Loss):\n",
    "\n",
    "\n",
    "    def __init__(self, batch_size: int, n_heads: int, **kwargs) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.n_heads = n_heads\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        size = self.batch_size\n",
    "        n_labels = y_pred.shape[-1]\n",
    "        # lower half is Z\n",
    "        Z = y_pred[0: size, :]\n",
    "        Z = K.expand_dims(Z, axis=2)\n",
    "        # upper half is Zbar\n",
    "        Zbar = y_pred[size: y_pred.shape[0], :]\n",
    "        Zbar = K.expand_dims(Zbar, axis=1)\n",
    "        # compute joint distribution (Eq 10.3.2 & .3)\n",
    "        P = K.batch_dot(Z, Zbar)\n",
    "        P = K.sum(P, axis=0)\n",
    "        # enforce symmetric joint distribution (Eq 10.3.4)\n",
    "        P = (P + K.transpose(P)) / 2.0\n",
    "        # normalization of total probability to 1.0\n",
    "        P = P / K.sum(P)\n",
    "        # marginal distributions (Eq 10.3.5 & .6)\n",
    "        Pi = K.expand_dims(K.sum(P, axis=1), axis=1)\n",
    "        Pj = K.expand_dims(K.sum(P, axis=0), axis=0)\n",
    "        Pi = K.repeat_elements(Pi, rep=n_labels, axis=1)\n",
    "        Pj = K.repeat_elements(Pj, rep=n_labels, axis=0)\n",
    "        P = K.clip(P, K.epsilon(), np.finfo(float).max)\n",
    "        Pi = K.clip(Pi, K.epsilon(), np.finfo(float).max)\n",
    "        Pj = K.clip(Pj, K.epsilon(), np.finfo(float).max)\n",
    "        # negative MI loss (Eq 10.3.7)\n",
    "        neg_mi = K.sum((P * (K.log(Pi) + K.log(Pj) - K.log(P))))\n",
    "        # each head contribute 1/n_heads to the total loss\n",
    "        return neg_mi / self.n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da500629-3439-4ebd-8d35-4f08e6c96319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IIC:\n",
    "    def __init__(self,\n",
    "                 iic_data_gen,\n",
    "                 n_heads,\n",
    "                 n_labels,\n",
    "                 backbone):\n",
    "        self.backbone = backbone\n",
    "        self._model = None\n",
    "        self.train_gen = iic_data_gen\n",
    "        self.n_labels = n_labels\n",
    "        self.n_heads = n_heads       \n",
    "\n",
    "\n",
    "    def build_model(self, **dense_kwargs):\n",
    "        \"\"\"Build the n_heads of the IIC model\n",
    "        \"\"\"\n",
    "        inputs = Input(shape=self.train_gen.sample_X.shape[1:], name='x')\n",
    "        x = self.backbone(inputs)\n",
    "        x = Flatten()(x)\n",
    "        # number of output heads\n",
    "        outputs = []\n",
    "        for i in range(self.n_heads):\n",
    "            name = \"z_head%d\" % i\n",
    "            outputs.append(Dense(self.n_labels,\n",
    "                                 name=name,\n",
    "                                 **dense_kwargs)(x))\n",
    "        self._model = Model(inputs, outputs, name='encoder')\n",
    "\n",
    "\n",
    "    def compile(self, **compile_kwargs):\n",
    "        mi_loss = MILoss(batch_size=self.train_gen.batch_size,\n",
    "                         n_heads=self.n_heads)\n",
    "        self._model.compile(loss=mi_loss, **compile_kwargs)\n",
    "\n",
    "\n",
    "    def train(self, **fit_kwargs):\n",
    "        self._model.fit(x=self.train_gen, **fit_kwargs)\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394205a-8631-4a90-9b84-62da105e03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_image_generator = ImageDataGenerator(\n",
    "    rotation_range=50\n",
    ")\n",
    "data_to_generator = data_arr['3']\n",
    "np.random.shuffle(data_to_generator)\n",
    "iic_paired_gen = IICDataPairGenerator(data_to_generator,\n",
    "                                      rotate_image_generator, 10)\n",
    "backbone = tf.keras.models.Sequential([\n",
    "    Input(iic_paired_gen.sample_X.shape[1:]),\n",
    "    Conv2D(filters=4, kernel_size=(16, 16)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPool2D(pool_size=(20, 20)),\n",
    "    Conv2D(filters=16, kernel_size=(3, 3), kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu')\n",
    "])\n",
    "\n",
    "iic_model = IIC(iic_paired_gen, n_heads=1, n_labels=2, backbone=backbone)\n",
    "iic_model.build_model(activation='softmax', kernel_regularizer=tf.keras.regularizers.l1(1e-3))\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "iic_model.compile(optimizer=optimizer)\n",
    "iic_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee8217-8e1c-454c-aa02-9137b06c9894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iic_model.train(epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e19200-c629-4ea5-94ff-ca39990a50bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_prob = pd.DataFrame(iic_model.model.predict(data_arr['3']), columns=['0_prob', '1_prob'])\n",
    "results_prob['keys'] = results_prob.index\n",
    "RANDOM_COEF = 15\n",
    "results_prob['final_label'] = results_prob['0_prob'].apply(lambda prob: 1 if prob <= 0.5 else -1)\n",
    "results_prob['x'] = results_prob['final_label'] + results_prob['final_label'] * np.random.random(size=len(results_prob)) * RANDOM_COEF\n",
    "results_prob['y'] = results_prob['x'] + results_prob['final_label'] * np.random.random(size=len(results_prob)) * RANDOM_COEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091382e-6784-47b6-b7cd-694a9c689139",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_badge_scatter(\n",
    "    df=results_prob,\n",
    "    img_provider=lambda key: OffsetImage(data_to_generator[int(key)][:, :, 0], zoom=0.1, alpha=1), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979a68d-9285-42f1-9144-e74410a3b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_to_generator[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7e783-6bee-4675-95f7-04471f35f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import cv2\n",
    "import plotly.express as px\n",
    "\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from ipywidgets import interact\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ec13c-3357-4bf8-bde2-c0794ba768f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7997b-d5f5-4e2e-a6a9-91d20039ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'archive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821e7f7-a1b8-4be3-b47f-edda39a71b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(DATA_FOLDER, 'cat_to_name.json'), 'r') as fin:\n",
    "    cat_to_name = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb88b09-21b8-4af5-b8d3-9b9b3434643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "COIN_TYPE_I, CURRENCY_I, COUNTRY_I = 0, 1, 2\n",
    "SEP = ','\n",
    "cat_to_name = {k: name.split(SEP) for k, name in cat_to_name.items()}\n",
    "cat_name_df = pd.DataFrame(cat_to_name).transpose()\n",
    "cat_name_df.rename(columns={0: 'coin type', 1: 'currency', 2: 'country'}, inplace=True)\n",
    "cat_name_df['class'] = cat_name_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45630d1-959c-49d3-baf2-27f692d8c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pathes = glob(join(DATA_FOLDER, 'coins', 'data', 'train', '*', '*'))\n",
    "test_data_pathes = glob(join(DATA_FOLDER, 'coins', 'data', 'test', '*', '*'))\n",
    "validation_data_pathes = glob(join(DATA_FOLDER, 'coins', 'data', 'validation', '*', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7b1e3-6184-4156-aeb9-d47e4b14dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coin_data(pathes: list[str]) -> dict[str, np.ndarray]:\n",
    "    CLASS_PATH_I = -2\n",
    "    FILE_PATH_I = -1\n",
    "    FILE_IDX_SEP = '__'\n",
    "    data = dict()\n",
    "    \n",
    "    for path in pathes:\n",
    "        coin_class = path.split(os.sep)[CLASS_PATH_I]\n",
    "        coin_idx = path.split(os.sep)[FILE_PATH_I].split(FILE_IDX_SEP)[0]\n",
    "        data[f'{coin_class}_{coin_idx}'] = tf.convert_to_tensor(\n",
    "            tf.keras.utils.load_img(path), dtype_hint=tf.float32\n",
    "        )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47e272-9bc8-4660-bd20-85325e438c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_coin_data(train_data_pathes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c1764-d7a5-4ea2-a8dc-00f53ba42243",
   "metadata": {},
   "source": [
    "## Detect images with front and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d0682-0e04-453f-b33d-9010b6cae780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMG_REL_THRESHOLD = 1.35\n",
    "train_img_rel = {\n",
    "    k: img.shape[1] / img.shape[0]\n",
    "    for k, img in train_data.items()\n",
    "}\n",
    "front_back_keys = [\n",
    "    k for k in train_img_rel.keys()\n",
    "    if train_img_rel[k] >= IMG_REL_THRESHOLD\n",
    "]\n",
    "front_back_map = {\n",
    "    class_val: [k for k in front_back_keys if k.split('_')[0] == class_val]\n",
    "    for class_val in cat_to_name.keys()\n",
    "}\n",
    "cat_name_df['front_back_keys'] = cat_name_df['class'].map(front_back_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f21617-3782-4878-9422-4f5dfc81fff3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### It is needed to detect front class and back class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849a7fd-fa72-4b85-90ea-0ae884cd3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def make_sobel_image(img_tensor: tf.Tensor) -> tf.Tensor:\n",
    "    if len(img_tensor.shape) == 3:\n",
    "        grad_sobel = tf.image.sobel_edges(tf.expand_dims(img_tensor, axis=0))\n",
    "    elif len(img_tensor.shape) == 4:\n",
    "        grad_sobel = tf.image.sobel_edges(img_tensor)\n",
    "    else:\n",
    "        raise AttributeError(\"Invalid image tensor shape, should be either 3 or 4\")\n",
    "\n",
    "    grad_module = tf.sqrt(tf.reduce_sum(grad_sobel ** 2, axis=-1))\n",
    "    return tf.reshape(grad_module, img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c9a21-4c08-4df6-913b-28270f08535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_LOAD = False\n",
    "IS_SAVE = False\n",
    "\n",
    "SAVE_PATH = join(DATA_FOLDER, 'train_edges_imgs.joblib')\n",
    "\n",
    "if not os.path.exists(SAVE_PATH) or FORCE_LOAD:\n",
    "    print('preprocessing...')\n",
    "    train_edge_imgs = {k: make_sobel_image(img)[:, :, 0] for k, img in train_data.items()}\n",
    "else:\n",
    "    print('loading from file...')\n",
    "    with open(SAVE_PATH, 'rb') as fin:\n",
    "        train_edge_imgs = joblib.load(fin)\n",
    "\n",
    "if IS_SAVE:\n",
    "    with open(SAVE_PATH, 'wb') as fout:\n",
    "        joblib.dump(train_edge_imgs, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8693a3-c482-4335-aee5-53224d20d15d",
   "metadata": {},
   "source": [
    "deleting the ucoin.net template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f684c7-8d38-482c-83bb-64333e6b0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucoin_text_templates_vertical = [\n",
    "    train_edge_imgs['1_001'][-408:-310, -22:].numpy(),\n",
    "    train_edge_imgs['1_007'][72:141, -15:].numpy()\n",
    "]\n",
    "ucoin_text_templates_horizontal = [\n",
    "    cv2.rotate(template, cv2.ROTATE_90_CLOCKWISE)\n",
    "    for template in ucoin_text_templates_vertical\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c0e13-7736-4206-8484-69b47c6f3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def view_template_detection(input_k=train_edge_imgs.keys()):\n",
    "    global ucoin_text_templates_horizontal\n",
    "    global ucoin_text_templates_vertical\n",
    "    \n",
    "    input_img = train_edge_imgs[input_k].numpy()\n",
    "    CORR_THRESHOLD = 0.9\n",
    "    detected_vert_indices = []\n",
    "    detected_horiz_indices = []\n",
    "    for horiz_template, vert_template in zip(\n",
    "        ucoin_text_templates_horizontal,\n",
    "        ucoin_text_templates_vertical\n",
    "    ):\n",
    "        vert_corr = cv2.matchTemplate(input_img, vert_template, cv2.TM_CCOEFF_NORMED)\n",
    "        horiz_corr = cv2.matchTemplate(input_img, horiz_template, cv2.TM_CCOEFF_NORMED)\n",
    "        detected_vert_indices.append(np.where(vert_corr >= CORR_THRESHOLD))\n",
    "        detected_horiz_indices.append(np.where(horiz_corr >= CORR_THRESHOLD))\n",
    "\n",
    "    print('detected vertical indices', detected_vert_indices)\n",
    "    print('detected horizontal indices', detected_horiz_indices)\n",
    "    \n",
    "    for i in range(len(detected_horiz_indices)):\n",
    "        for pt in zip(*detected_vert_indices[i]):\n",
    "            cv2.rectangle(\n",
    "                input_img,\n",
    "                (pt[1], pt[0]),\n",
    "                (pt[1] + ucoin_text_templates_vertical[i].shape[1],\n",
    "                 pt[0] + ucoin_text_templates_vertical[i].shape[0]),\n",
    "                255,\n",
    "                2\n",
    "            )\n",
    "        for pt in zip(*detected_horiz_indices[i]):\n",
    "            cv2.rectangle(\n",
    "                input_img,\n",
    "                (pt[1], pt[0]),\n",
    "                (pt[1] + ucoin_text_templates_horizontal[i].shape[1],\n",
    "                 pt[0] + ucoin_text_templates_horizontal[i].shape[0]),\n",
    "                255,\n",
    "                2\n",
    "            )\n",
    "    \n",
    "    plt.imshow(input_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2452cd-6511-469d-98c2-a8fe667f3dfd",
   "metadata": {},
   "source": [
    "### crop images (delete vertical ucoin.net band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e7c5e-8784-4785-8a4b-0bcfbf119ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_LOAD = False\n",
    "IS_SAVE = True\n",
    "SAVE_PATH = join(DATA_FOLDER, 'ucoin_cropped_train_edges_imgs.joblib')\n",
    "\n",
    "cropped_edge_imgs = dict()\n",
    "CORR_THRESHOLD = 0.9\n",
    "\n",
    "if not os.path.exists(SAVE_PATH) or FORCE_LOAD: \n",
    "    for key in train_edge_imgs:\n",
    "        input_img = train_edge_imgs[key].numpy()\n",
    "        detected_vert_indices = []\n",
    "    \n",
    "        for vert_template in ucoin_text_templates_vertical:\n",
    "            vert_corr = cv2.matchTemplate(input_img, vert_template, cv2.TM_CCOEFF_NORMED)\n",
    "            detected_vert_indices.append(np.where(vert_corr >= CORR_THRESHOLD))\n",
    "    \n",
    "        template_xs = []\n",
    "        for i in range(len(detected_vert_indices)):\n",
    "            for pt in zip(*detected_vert_indices[i]):\n",
    "                template_xs.append(pt[1])\n",
    "        \n",
    "        if len(template_xs) != 0:\n",
    "            x_band_mean = int(np.mean(template_xs))\n",
    "        \n",
    "            # the algorithm of determing the position of the band\n",
    "            # (left side/right side)\n",
    "            if x_band_mean > (input_img.shape[1] / 2.0):\n",
    "                cropped_edge_imgs[key] = input_img[:, :x_band_mean]\n",
    "            else:\n",
    "                cropped_edge_imgs[key] = input_img[:, x_band_mean:]\n",
    "        else:\n",
    "            cropped_edge_imgs[key] = input_img\n",
    "else:\n",
    "    print('loading from file...')\n",
    "    with open(SAVE_PATH, 'rb') as fin:\n",
    "        cropped_edge_imgs = joblib.load(fin)\n",
    "\n",
    "if IS_SAVE:\n",
    "    print('saving results...')\n",
    "    with open(SAVE_PATH, 'wb') as fout:\n",
    "        joblib.dump(cropped_edge_imgs, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca1e36-130e-40a5-83ba-183f7a2df402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @interact\n",
    "# def view_imgs(input_key=list(cropped_edge_imgs.keys())):\n",
    "#     plt.imshow(cropped_edge_imgs[input_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4db10-35d7-4ab3-a667-e512120a13bf",
   "metadata": {},
   "source": [
    "### using Embedding algorithms to cluster by two images (front and back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce01f5-eed8-4a82-8105-c7e440b2bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_badge_scatter(\n",
    "    df: pd.DataFrame,\n",
    "    img_provider:Callable[[str], OffsetImage],\n",
    "    **subplot_kwargs\n",
    ") -> tuple:\n",
    "    REQ_COLS = {'x', 'y', 'keys'}\n",
    "    if len(set(df.columns).union(REQ_COLS)) > len(df.columns):\n",
    "        raise ValueError(f'Required cols for the input dataframe {REQ_COLS}')\n",
    "        \n",
    "    fig, ax = plt.subplots(**subplot_kwargs)\n",
    "    ax.scatter(df['x'], df['y'])\n",
    "    for index, row in df.iterrows():\n",
    "        ab = AnnotationBbox(getImage(row['keys']), (row['x'], row['y']),\n",
    "                            frameon=False)\n",
    "        ax.add_artist(ab)\n",
    "    plt.grid(True)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc30e49-08fa-44d5-b2b6-7419fe60f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(key):\n",
    "    return OffsetImage(cropped_edge_imgs[key], zoom=0.25, alpha=1)\n",
    "\n",
    "\n",
    "@interact\n",
    "def view_embed(input_class=cat_name_df['class'].to_list()):\n",
    "    IMG_SIZE = [100, 100]\n",
    "    embed_m = TSNE(n_components=2, perplexity=5)\n",
    "    \n",
    "    input_flatten_imgs = {\n",
    "        key: np.expand_dims(\n",
    "            cv2.resize(img, IMG_SIZE).astype(np.int32).flatten(),\n",
    "            axis=0\n",
    "        )\n",
    "        for key, img in cropped_edge_imgs.items()\n",
    "        if key.split('_')[0] == input_class \n",
    "            and key not in cat_name_df[cat_name_df['class'] == input_class]\\\n",
    "                           .iloc[0]['front_back_keys']\n",
    "    }\n",
    "    \n",
    "    iter_keys = sorted(input_flatten_imgs.keys())\n",
    "    data_to_embed = np.concatenate([input_flatten_imgs[k] for k in iter_keys], axis=0)\n",
    "    \n",
    "    res = pd.DataFrame(embed_m.fit_transform(data_to_embed), columns=['x', 'y'])\n",
    "    res['keys'] = iter_keys\n",
    "    fig, ax = make_badge_scatter(res, getImage, figsize=(20, 20))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b4f76-27c2-470e-a5a8-3ed1b7188057",
   "metadata": {},
   "source": [
    "- 2 class has 1 element of the 1 class\n",
    "- 15 class has 1 element of the 16 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bedfab-89ed-4413-a558-d7651f254ea1",
   "metadata": {},
   "source": [
    "TODO: using IIC to cluster front/back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7cf929-1a28-43a9-b5af-6074d05041c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
